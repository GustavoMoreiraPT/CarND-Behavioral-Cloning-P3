{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data collected from the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "\n",
    "lines = []\n",
    "with open('simulator_images/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "correction = 0.2\n",
    "images = []\n",
    "steering_angles = []\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('\\\\')[-1] #windows in local environment\n",
    "        current_path = 'simulator_images/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        if i == 1: #left image\n",
    "            steering_angle = float(line[3]) + correction\n",
    "            steering_angles.append(steering_angle)\n",
    "        if i == 2: #right image\n",
    "            steering_angle = float(line[3]) - correction\n",
    "            steering_angles.append(steering_angle)\n",
    "        if i == 0: #center image\n",
    "            steering_angle = float(line[3])\n",
    "            steering_angles.append(steering_angle)\n",
    "        \n",
    "    \n",
    "augmented_images, augmented_steering_angles = [], []\n",
    "for image, steering_angle in zip(images, steering_angles):\n",
    "    augmented_images.append(image)\n",
    "    augmented_steering_angles.append(steering_angle)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_steering_angles.append(steering_angle*-1.0)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative to load image as memory restrictions started to be visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 78614\n",
      "Validation samples: 19654\n",
      "78614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('training_simulator_images/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "correction = 0.2\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples*6, test_size=0.2)\n",
    "\n",
    "print(\"Train samples: \" + str(len(train_samples)))\n",
    "print(\"Validation samples: \" + str(len(validation_samples)))\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    print(num_samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = 'training_simulator_images/IMG/'+batch_sample[0].split('\\\\')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                #repeat process for left image\n",
    "                left_name = 'training_simulator_images/IMG/'+batch_sample[1].split('\\\\')[-1]\n",
    "                left_image = cv2.imread(left_name)\n",
    "                left_angle = float(batch_sample[3]) + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                #repeat process for right image\n",
    "                right_name = 'training_simulator_images/IMG/'+batch_sample[2].split('\\\\')[-1]\n",
    "                right_image = cv2.imread(right_name)\n",
    "                right_angle = float(batch_sample[3]) - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "                #augmented images\n",
    "                images.append(cv2.flip(center_image, 1))\n",
    "                images.append(cv2.flip(left_image, 1))\n",
    "                images.append(cv2.flip(right_image, 1))\n",
    "                angles.append(center_angle*-1.0)\n",
    "                angles.append(left_angle*-1.0)\n",
    "                angles.append(right_angle*-1.0)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "# Set our batch size\n",
    "batch_size=6\n",
    "\n",
    "print(len(train_samples))\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of images collected from training on Udacity Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49134\n",
      "49134\n",
      "98268\n",
      "98268\n"
     ]
    }
   ],
   "source": [
    "# this is no longer used\n",
    "\n",
    "print(len(steering_angles))\n",
    "print(len(images))\n",
    "\n",
    "print(len(augmented_steering_angles))\n",
    "print(len(augmented_images)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data into numpy arrays as Keras requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.1 GiB for an array with shape (98268, 160, 320, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2de6ab30e253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#first used images and angles, then augmented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_images\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# dataset for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_steering_angles\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#labels, which in this case are the steering angles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.1 GiB for an array with shape (98268, 160, 320, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#first used images and angles, then augmented\n",
    "X_train = np.array(augmented_images) # dataset for training\n",
    "y_train = np.array(augmented_steering_angles) #labels, which in this case are the steering angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple neural networks with keras just to validate that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_15_216.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_32_251.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_20_829.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_21_33_495.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_46_164.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_12_103.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_25_379.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_48_14_279.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_24_133.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_34_495.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_15_44_929.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_04_702.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_19_22_905.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_51_838.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_55_029.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_03_949.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_52_010.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_49_616.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_14_56_472.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_46_18_855.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_56_833.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_39_744.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_46_42_077.jpg\n",
      "    1/13103 [..............................] - ETA: 1:06:28 - loss: 9659.6357training_simulator_images/IMG/center_2020_06_01_13_21_32_833.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_26_444.jpg\n",
      "    2/13103 [..............................] - ETA: 39:15 - loss: 16894021.8179training_simulator_images/IMG/center_2020_06_01_14_18_23_242.jpgtraining_simulator_images/IMG/center_2020_06_01_14_16_44_443.jpg\n",
      "\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_43_834.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_14_52_471.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_09_092.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_38_440.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_22_25_838.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_15_17_770.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_22_39_140.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_35_638.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_38_638.jpg\n",
      "\btraining_simulator_images/IMG/center_2020_06_01_09_47_34_756.jpg\n",
      "    3/13103 [..............................] - ETA: 40:10 - loss: 30200145.2119training_simulator_images/IMG/center_2020_06_01_09_47_10_024.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_34_564.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_32_180.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_46_17_295.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_30_896.jpgtraining_simulator_images/IMG/center_2020_06_01_09_44_44_144.jpg\n",
      "\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_03_443.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_02_391.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_21_12_655.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_14_531.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_30_895.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_59_819.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_09_806.jp\n",
      "    4/13103 [..............................] - ETA: 42:57 - loss: 27966291.9089training_simulator_images/IMG/center_2020_06_01_13_24_12_230.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_04_999.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_28_102.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_34_53_283.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_37_517.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_32_089.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_46_17_722.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_55_22_913.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_35_381.jpgtraining_simulator_images/IMG/center_2020_06_01_14_16_33_706.jpg\n",
      "\n",
      "training_simulator_images/IMG/center_2020_06_01_14_19_04_926.jpgtraining_simulator_images/IMG/center_2020_06_01_09_45_57_606.jpg\n",
      "\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_17_659.jpgtraining_simulator_images/IMG/center_2020_06_01_14_14_43_916.jpg\n",
      "\n",
      "    5/13103 [..............................] - ETA: 45:21 - loss: 24597140.9271training_simulator_images/IMG/center_2020_06_01_09_34_56_373.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_13_873.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_48_916.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_30_712.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_22_40_728.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_43_492.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_10_805.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_48_09_013.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_17_966.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_54_01_019.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_00_013.jpg\n",
      "    6/13103 [..............................] - ETA: 44:40 - loss: 25640884.4393training_simulator_images/IMG/center_2020_06_01_13_22_58_540.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_13_919.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_53_275.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_37_971.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_25_14_467.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_48_396.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_25_03_337.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_14_34_767.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_22_335.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_55_22_991.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_34_49_078.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_38_753.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_07_815.jpg\n",
      "    7/13103 [..............................] - ETA: 46:20 - loss: 24665054.3765training_simulator_images/IMG/center_2020_06_01_14_18_09_665.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_16_692.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_00_885.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_14_48_089.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_15_53_890.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_20_613.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_35_945.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_28_840.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_18_471.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_16_530.jpg\n",
      "    8/13103 [..............................] - ETA: 46:32 - loss: 21811550.8920\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_31_315.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_34_52_724.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_53_876.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_54_713.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_44_935.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_20_651.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_20_725.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_09_894.jpg\n",
      "    9/13103 [..............................]training_simulator_images/IMG/center_2020_06_01_09_47_15_924.jpg - ETA: 45:07 - loss: 21445299.6817\n",
      "training_simulator_images/IMG/center_2020_06_01_09_48_16_415.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_25_11_560.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_15_53_960.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_01_358.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_05_497.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_20_872.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_48_012.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_10_516.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_20_316.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_13_387.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_simulator_images/IMG/center_2020_06_01_09_47_56_202.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_15_29_074.jpg\n",
      "   10/13103 [..............................] - ETA: 46:02 - loss: 21856058.1136training_simulator_images/IMG/center_2020_06_01_09_47_27_429.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_00_999.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_11_906.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_05_139.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_22_37_220.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_04_715.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_22_823.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_32_436.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_45_10_294.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_27_615.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_41_803.jpg\n",
      "   11/13103 [..............................] - ETA: 45:30 - loss: 20162172.8078training_simulator_images/IMG/center_2020_06_01_10_23_13_616.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_46_05_009.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_07_025.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_54_377.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_36_879.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_13_061.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_14_074.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_56_476.jpg\n",
      "   12/13103 [..............................] - ETA: 45:37 - loss: 18910131.9071training_simulator_images/IMG/center_2020_06_01_14_14_43_040.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_35_21_029.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_21_00_037.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_48_13_723.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_24_06_182.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_17_16_316.jpg\n",
      "   13/13103 [..............................] - ETA: 45:54 - loss: 18957852.5297training_simulator_images/IMG/center_2020_06_01_09_36_35_740.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_36_33_454.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_14_44_436.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_36_540.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_18_57_359.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_58_922.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_44_59_979.jpg\n",
      "   14/13103 [..............................] - ETA: 45:08 - loss: 18310852.7776training_simulator_images/IMG/center_2020_06_01_09_37_00_752.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_19_16_711.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_38_32_003.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_10_23_11_139.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_47_36_837.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_37_13_873.jpg\n",
      "   15/13103 [..............................] - ETA: 44:36 - loss: 17109936.4257training_simulator_images/IMG/center_2020_06_01_10_21_35_609.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_57_794.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_13_23_40_838.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_14_16_44_526.jpg\n",
      "training_simulator_images/IMG/center_2020_06_01_09_34_24_581.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-a8880f51f101>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             epochs=5, verbose=1, shuffle=1)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m                     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Project3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "import math\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(160, 320, 3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, \n",
    "            steps_per_epoch=math.ceil(len(train_samples)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_samples)/batch_size), \n",
    "            epochs=5, verbose=1, shuffle=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusta\\Anaconda3\\envs\\Project3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3859 samples, validate on 965 samples\n",
      "Epoch 1/2\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 2.7471 - val_loss: 0.9103\n",
      "Epoch 2/2\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 1.8588 - val_loss: 2.9442\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=2) #2 epochs\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing training dataset against LeNet with changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19654\n",
      "78614\n",
      "  311/13103 [..............................] - ETA: 4:14:52 - loss: 0.1424"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import math\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0, 0))))\n",
    "#results into an image of shape 156x316x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "\n",
    "#results into images of shape 152x312x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "#pooling layers\n",
    "#by applying a filter of 2x2, scales down the image to 72x156x60\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 68x152x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "#results into an image shape of 34x76x60\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 30x72x30\n",
    "model.add(Conv2D(30, (5,5), activation='relu'))\\\n",
    "#results into and image shape of 15x36x30\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 11x32x30\n",
    "#model.add(Conv2D(15, (5,5), activation='relu'))\\\n",
    "#results into and image shape of 6x18x15\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#6x18x15 = 720 nodes\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(500))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(train_generator, \n",
    "            steps_per_epoch=math.ceil(len(train_samples)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_samples)/batch_size), \n",
    "            epochs=5, verbose=1, shuffle=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history_object.history.keys())\n",
    "\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
