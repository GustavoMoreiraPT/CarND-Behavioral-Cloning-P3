{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data collected from the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "\n",
    "lines = []\n",
    "with open('simulator_images/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "correction = 0.2\n",
    "images = []\n",
    "steering_angles = []\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('\\\\')[-1] #windows in local environment\n",
    "        current_path = 'simulator_images/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        if i == 1: #left image\n",
    "            steering_angle = float(line[3]) + correction\n",
    "            steering_angles.append(steering_angle)\n",
    "        if i == 2: #right image\n",
    "            steering_angle = float(line[3]) - correction\n",
    "            steering_angles.append(steering_angle)\n",
    "        if i == 0: #center image\n",
    "            steering_angle = float(line[3])\n",
    "            steering_angles.append(steering_angle)\n",
    "        \n",
    "    \n",
    "augmented_images, augmented_steering_angles = [], []\n",
    "for image, steering_angle in zip(images, steering_angles):\n",
    "    augmented_images.append(image)\n",
    "    augmented_steering_angles.append(steering_angle)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_steering_angles.append(steering_angle*-1.0)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of images collected from training on Udacity Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14472\n",
      "14472\n",
      "28944\n",
      "28944\n"
     ]
    }
   ],
   "source": [
    "print(len(steering_angles))\n",
    "print(len(images))\n",
    "\n",
    "print(len(augmented_steering_angles))\n",
    "print(len(augmented_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data into numpy arrays as Keras requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#first used images and angles, then augmented\n",
    "X_train = np.array(augmented_images) # dataset for training\n",
    "y_train = np.array(augmented_steering_angles) #labels, which in this case are the steering angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple neural networks with keras just to validate that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusta\\Anaconda3\\envs\\Project3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3859 samples, validate on 965 samples\n",
      "Epoch 1/7\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 15498048.1850 - val_loss: 12651.3437\n",
      "Epoch 2/7\n",
      "3859/3859 [==============================] - 6s 2ms/step - loss: 7515.4344 - val_loss: 5288.1127\n",
      "Epoch 3/7\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 4235.9304 - val_loss: 4710.6614\n",
      "Epoch 4/7\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 3520.3874 - val_loss: 2832.3550\n",
      "Epoch 5/7\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 2528.1491 - val_loss: 5740.8667\n",
      "Epoch 6/7\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 2292.3738 - val_loss: 2820.5066\n",
      "Epoch 7/7\n",
      "3859/3859 [==============================] - 6s 2ms/step - loss: 2304.2033 - val_loss: 2258.6188\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(160, 320, 3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7) #7 epochs\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusta\\Anaconda3\\envs\\Project3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3859 samples, validate on 965 samples\n",
      "Epoch 1/2\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 2.7471 - val_loss: 0.9103\n",
      "Epoch 2/2\n",
      "3859/3859 [==============================] - 7s 2ms/step - loss: 1.8588 - val_loss: 2.9442\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=2) #2 epochs\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing training dataset against LeNet with changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23155 samples, validate on 5789 samples\n",
      "Epoch 1/5\n",
      "14208/23155 [=================>............] - ETA: 3:36 - loss: 0.0278"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0, 0))))\n",
    "#results into an image of shape 156x316x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "\n",
    "#results into images of shape 152x312x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "#pooling layers\n",
    "#by applying a filter of 2x2, scales down the image to 72x156x60\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 68x152x60\n",
    "model.add(Conv2D(60, (5,5), activation='relu'))\n",
    "#results into an image shape of 34x76x60\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 30x72x30\n",
    "model.add(Conv2D(30, (5,5), activation='relu'))\\\n",
    "#results into and image shape of 15x36x30\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#results into an image shape of 11x32x30\n",
    "#model.add(Conv2D(15, (5,5), activation='relu'))\\\n",
    "#results into and image shape of 6x18x15\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#6x18x15 = 720 nodes\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(500))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, batch_size = 12, shuffle=True, epochs=5)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
